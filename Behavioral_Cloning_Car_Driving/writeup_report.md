# **Behavioral Cloning** 

**Behavioral Cloning Project**

The goals / steps of this project are the following:
* Use the simulator to collect data of good driving behavior
* Build, a convolution neural network in Keras that predicts steering angles from images
* Train and validate the model with a training and validation set
* Test that the model successfully drives around track one without leaving the road
* Summarize the results with a written report


### Files Submitted & Code Quality

#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode

My project includes the following files:
* model.py containing the script to create and train the model
* drive.py for driving the car in autonomous mode
* model.h5 containing a trained convolution neural network 
* writeup_report.md summarizing the results

Using the Udacity provided simulator and my drive.py file, I was able to test my model by driving autonomously around the track by executing:

```
python drive.py model.h5
```

Video of driving the car was generated by executing:

```
python drive.py model.h5 run1
python video.py run1 --fps 48
```


### Dataset

I used training dataset provided by Udacity. I use all 3 positions of camera with correction of 0.25 , i.e addition of 0.25 to steering angle for left-positioned camera and substraction of 0.25 for right-positioned camera.

I could have self-produced ore data but due to time constraint, I only used Udacity dataset

Moreover, after unable to complete a whole lap, I follow advice from forum and decided to randomly choose camera to select from

The dataset is split into 20% of test set. Also, the training set is shuffled before training

### Data Preprocessing

My pre-processing pipeline including:

```
- Data augmentation: Fliping the image horizontal randomly 
- Cropping the image to 66x200 to fit NVIDIA model
- Normalization and Mean centering
```

Again, Flipping the image randomly was recommended by forum mentor.


### Model Architecture and Training Strategy

In my first attempt, I used 9-layers network from end to end learning for self-driving cars by NVIDIA as recommended by Udacity

    
|Layer   |type    |output filter/neurons|
|--------|--------|--------|
|1       |conv    |24      |
|2       |conv    |36      |
|3       |conv    |48      |
|4       |conv    |64      |
|5       |conv    |64      |
|6       |flattern|1164    |
|7       |relu    |100     |
|8       |relu    |50      |
|9       |relu    |10      |
|10      |relu    |1       |


However, I detected overfitting in my first attempt as they training and validation loss did not converge, hence I tried to combat overfitting in the second model by applying regulation, i.e dropout

|Layer   |type    |output filter/neurons|
|--------|--------|--------|
|1       |conv    |24      |
|        |dropout |        |
|2       |conv    |36      |
|        |dropout |        |
|3       |conv    |48      |
|        |dropout |        |
|4       |conv    |64      |
|5       |conv    |64      |
|6       |flattern|1164    |
|7       |relu    |100     |
|8       |relu    |50      |
|9       |relu    |10      |
|10      |relu    |1       |

For every time of training and parameter tunning, the model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.

Final Model parameters:

```
- Optimizer: Adam optimizer, so the learning rate was not tuned manually 
- Epoch: 5
- Batch size: 32
```